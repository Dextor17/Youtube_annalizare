{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\noswear\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Import dataset\n",
    "dataset = pd.read_csv('data_v4.csv')\n",
    "\n",
    "#datasets = pd.read_table('data_v4.tsv')\n",
    "\n",
    "# library to clean data\n",
    "import re\n",
    "\n",
    "# Natural Language Tool Kit\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# to remove stopword\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# for Stemming propose\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Initialize empty array\n",
    "# to append clean text\n",
    "corpus = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    1\n",
       "20    1\n",
       "21    1\n",
       "22    1\n",
       "23    1\n",
       "24    1\n",
       "25    0\n",
       "26    1\n",
       "27    1\n",
       "28    1\n",
       "29    1\n",
       "30    1\n",
       "31    1\n",
       "32    1\n",
       "33    1\n",
       "34    1\n",
       "35    1\n",
       "36    1\n",
       "37    1\n",
       "38    1\n",
       "39    1\n",
       "40    1\n",
       "41    1\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sn', 'comments', 'polarity'], dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = re.sub('[^a-zA-Z]', ' ', dataset['comments'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 (reviews) rows to clean\n",
    "for i in range(0, 42):\n",
    "    # column : \"Review\", row ith\n",
    "    comments = re.sub('[^a-zA-Z]', ' ', dataset['comments'][i])\n",
    "\n",
    "    # convert all cases to lower cases\n",
    "    comments = comments.lower()\n",
    "\n",
    "    # split to array(default delimiter is \" \")\n",
    "    comments = comments.split()\n",
    "\n",
    "    # creating PorterStemmer object to\n",
    "    # take main stem of each word\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    # loop for stemming each word\n",
    "    # in string array at ith row\n",
    "    review = [ps.stem(word) for word in comments\n",
    "              if not word in set(stopwords.words('english'))]\n",
    "\n",
    "    # rejoin all string array elements\n",
    "    # to create back into a string\n",
    "    comments = ' '.join(comments)\n",
    "\n",
    "    # append each string to create\n",
    "    # array of clean text\n",
    "    corpus.append(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sir plz provide videoes on c net',\n",
       " 'nice video sir thanks for this video',\n",
       " 'generalization ka topic ka v video dalo plz',\n",
       " 'sir i need interview qns about dbms sir sir nice video superb explanation',\n",
       " 'amazing teaching sir',\n",
       " 'sir sid should be instead of at',\n",
       " 'i m understand normlization after watchinh videos that video this vedio thanku sir',\n",
       " 'at row level there are repeated rows how can we add primary key',\n",
       " 'bhai you are so helpful',\n",
       " '',\n",
       " 'sir hmme poly mai sql pr lesson hai sir pls us lesson pr video bnaie pls pls sir reply',\n",
       " 'paji thanks',\n",
       " 'very nice explanation sir keep it up',\n",
       " 'sir th and th normal form bhi karwado',\n",
       " 'gurujee shandhar jabardast zindabad',\n",
       " 'you are doing great job bro',\n",
       " 'your videos are great pls make videos on algarithms and data structures',\n",
       " 'best video ever',\n",
       " 'super class sir',\n",
       " 'sir u have great teaching skills even a single person u have nothing knowledge about dbms will get understood easily by just watching ur videos hope u will cross million sub at the earliest',\n",
       " 'execlent technique of explanation',\n",
       " 'sir please dijkstra algorithms make da video',\n",
       " 'sir apki krpa se m pas ho jauga',\n",
       " 'thank you so much sir m rdy for the final exam',\n",
       " 'sir thank you so much for nice explanation',\n",
       " 'hi sir u have to update sid not right for where condition correct me if i am wrong at time',\n",
       " 'sir can you make a videos lecture of coa for gate preparation',\n",
       " 'sir aap bahut accha padhate ho ur are my favourite teacher because of u i get good marks in my os subject without coaching and attending college classes thanku so much sir ur great bt iss video me aap thode sad lg rahe the tabiyat kharab hoga sayad apka once again thanks',\n",
       " 'ty sr',\n",
       " 'sir is video mai udas udas kyu lag rahe ho',\n",
       " 'excellent lectures but only constraint is hindi pls try to explain the concept in hindi and english also so everyone will be benifitted',\n",
       " 'sir aap algorithm par v video bnaiye plz sir',\n",
       " 'thanku so much sir',\n",
       " 'once again you ve proved that you are good explainer',\n",
       " 'sir sid of amrit pal is not',\n",
       " 'sir u teaching is amazing but y teaching only hindi medium',\n",
       " 'it officer',\n",
       " 'subscribed',\n",
       " 'i don t have words to thanking u for all ur video its all are greate and very easy to understand thnq so much sir',\n",
       " 'finally a decent teacher who teach in both hindi n elglish very well sir',\n",
       " 'sir plzz normalization k all type k tutorials upload kr dien mera exam hai main ny tyari krni hai thanks in advance',\n",
       " 'very nice explanation will u plz upload videos on computer orgnization']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:, 2].values\n",
    "y = y.astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# experiment with to get better results\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "# X contains corpus (dependent variable)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "X\n",
    "# y contains answers if review\n",
    "# is positive or negative\n",
    "y = dataset.iloc[:, 2].values\n",
    "y = y.astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1] [[ 0  1]\n",
      " [ 0 10]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x5f92f30>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5a364f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting the dataset into\n",
    "# the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# experiment with \"test_size\"\n",
    "# to get better results\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Fitting Random Forest Classification\n",
    "# to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_estimators can be said as number of\n",
    "# trees, experiment with n_estimators\n",
    "# to get better results\n",
    "model = RandomForestClassifier(n_estimators=501,\n",
    "                               criterion='entropy')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm\n",
    "print(y_pred,cm)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
